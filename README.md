
# Online Eye-Tracking Experiment

This project is a web-based eye-tracking experiment using Flask, JavaScript, WebGazer.js, and Python. It lets participants complete calibration, view randomized trials with images and audio, and records their gaze data for reaction time and gaze pattern analysis.

All gaze data is saved automatically to Excel files for later analysis.

---

## ğŸ”¬ Features

- Consent + Participant ID collection before trials.
- Calibration using 9 evenly spaced clickable points.
- Real-time gaze tracking via WebGazer.js.
- Images + Audio stimuli randomized across trials.
- Flexible trial types: silent, slow (casual audio), fast (rushed audio).
- Pauses with instructions between each trial.
- Reaction time estimation and gaze logging.
- Automatic Excel export of gaze data.
- Graphing script for reaction times & gaze scatter plots.
- Participant metadata saved with data files.

---

## ğŸ§  Technologies Used

- Python 3.11
- Flask
- JavaScript + WebGazer.js
- HTML5 / CSS3
- Pandas + OpenPyXL
- Matplotlib + Seaborn (for data analysis)
- Render (for online deployment)

---

## ğŸš€ How to Run Locally

### Step 1: Clone the repository
```bash
git clone https://github.com/LuisR-ecu/Onlline-Eyetracking.git
cd Onlline-Eyetracking
```

### Step 2: Create and activate a virtual environment
```bash
python -m venv venv
# Mac/Linux
source venv/bin/activate
# Windows
venv\Scripts\activate
```

### Step 3: Install dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Run the server
```bash
python server.py
```

Then open your browser and go to:

[http://localhost:5000](http://localhost:5000)

---

## ğŸ“ Project Structure

```
/static/         â†’ Images and audio files used in the experiment  
/templates/      â†’ index.html (frontend interface)  
server.py        â†’ Flask backend server  
analyze_data.py  â†’ Script to analyze saved gaze data  
requirements.txt â†’ Python dependencies  
gaze_data/       â†’ Folder where Excel files are saved after each participant completes
```

---

## ğŸ” Data Collected

Each gaze data Excel file contains:

- `x` â†’ X coordinate (pixels)
- `y` â†’ Y coordinate (pixels)
- `t` â†’ Timestamp (milliseconds from trial start)
- `trial` â†’ Trial number
- `type` â†’ Trial type (silent, slow, fast)

---

## ğŸ“Š Data Analysis

After running an experiment, set the correct filename in **analyze_data.py** and run:

```bash
python analyze_data.py
```

Youâ€™ll get:

- Reaction Time Plot (first gaze timestamp per trial).
- Gaze Scatter Plot (XY positions colored by trial).

---

## ğŸ“ Participant Instructions (for pauses between trials)

- **Silent** â†’ Read each instruction and look at the matching image before continuing.
- **Slow/Fast** â†’ Listen to the audio instruction and look at the matching image.

---

## ğŸŒ Deployment

This app is also configured for deployment on Render.com.  
(Instructions and production configuration available on request).

---

## ğŸ‘¤ Author

**Luis Ramirez**  
Undergraduate Research Assistant  
B.A. in Computer Science â€” East Carolina University (2023â€“2026)  
ğŸ“„ [Resume / Research Profile](www.linkedin.com/in/ramirez-luis-hernandez)
